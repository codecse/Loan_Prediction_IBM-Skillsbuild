{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(598, 13)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('LoanApprovalPrediction.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 598 entries, 0 to 597\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            598 non-null    object \n",
      " 1   Gender             598 non-null    object \n",
      " 2   Married            598 non-null    object \n",
      " 3   Dependents         586 non-null    float64\n",
      " 4   Education          598 non-null    object \n",
      " 5   Self_Employed      598 non-null    object \n",
      " 6   ApplicantIncome    598 non-null    int64  \n",
      " 7   CoapplicantIncome  598 non-null    float64\n",
      " 8   LoanAmount         577 non-null    float64\n",
      " 9   Loan_Amount_Term   584 non-null    float64\n",
      " 10  Credit_History     549 non-null    float64\n",
      " 11  Property_Area      598 non-null    object \n",
      " 12  Loan_Status        598 non-null    object \n",
      "dtypes: float64(5), int64(1), object(7)\n",
      "memory usage: 60.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender                0\n",
       "Married               0\n",
       "Dependents           12\n",
       "Education             0\n",
       "Self_Employed         0\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           21\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       49\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "598"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Loan_ID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Loan_ID column\n",
    "data.drop(['Loan_ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum().sum()\n",
    "# 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Gender = data.Gender.map({'Male': 0, 'Female':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "obj = (data.dtypes == 'object')\n",
    "for col in list(obj[obj].index):\n",
    "    data[col] = label_encoder.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    data[col] = data[col].fillna(data[col].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(['Loan_Status'], axis=1)\n",
    "y = data.Loan_Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in /opt/anaconda3/lib/python3.8/site-packages (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=1.1.1 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.3 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.5.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.8/site-packages (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR = 81.66666666666667\n",
      "LDA = 82.22222222222221\n",
      "KNN = 66.11111111111111\n",
      "CART = 74.44444444444444\n",
      "NB = 82.77777777777777\n",
      "SVC = 74.44444444444444\n",
      "RC = 82.22222222222221\n",
      "RF = 80.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(max_iter=1000)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVC', SVC()))\n",
    "models.append(('RC', RidgeClassifier()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "\n",
    "\n",
    "def modeling(model):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    return accuracy_score(y_test, y_pred) * 100\n",
    "     \n",
    "for name, model in models:\n",
    "    print(f'{name} = {modeling(model)}')\n",
    "     \n",
    "LR = 80.83333333333333\n",
    "LDA = 82.5\n",
    "KNN = 63.74999999999999\n",
    "CART = 68.33333333333333\n",
    "NB = 81.66666666666667\n",
    "SVC = 69.16666666666667\n",
    "RC = 82.91666666666667\n",
    "RF = 81.66666666666667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "\n",
    "# load the data\n",
    "data = pd.read_csv('LoanApprovalPrediction.csv')\n",
    "# Drop Loan_ID column\n",
    "data.drop(['Loan_ID'], axis=1, inplace=True)\n",
    "# convert to int datatype\n",
    "label_encoder = LabelEncoder()\n",
    "obj = (data.dtypes == 'object')\n",
    "for col in list(obj[obj].index):\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "# fill in missing rows\n",
    "for col in data.columns:\n",
    "    data[col] = data[col].fillna(data[col].mean())\n",
    "# divide model into features and target variable\n",
    "x = data.drop(['Loan_Status'], axis=1)\n",
    "y = data.Loan_Status\n",
    "\n",
    "# divide into training and testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=7)\n",
    "# define the model\n",
    "model = RidgeClassifier()\n",
    "# fit the model on the training data\n",
    "model.fit(x_train, y_train)\n",
    "#save the train model\n",
    "with open('train_model.pkl', mode='wb') as pkl:\n",
    "    pickle.dump(model, pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
